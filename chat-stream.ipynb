{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe49d241-94f3-4685-94dc-4c0ec21208da",
   "metadata": {},
   "source": [
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55800605-c9b1-40c9-8c12-fb17de2876a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part, Tool, ChatSession, FunctionDeclaration\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "from vertexai.preview.generative_models import grounding\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470424ae-972c-4f13-b3e0-15e50432f5c6",
   "metadata": {},
   "source": [
    "Set your project variables. Change \"YOUR_PROJECT_ID\" to your GCP project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a33169-d938-4185-8a08-d48cbee56958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"YOU_PROJECT_ID\"\n",
    "location = \"global\"\n",
    "region = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b485a0d-aaa3-4f04-b411-3198c3e3d6f8",
   "metadata": {},
   "source": [
    "Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18c7a8-c4e8-4002-bf95-36def8fb580f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-001\",\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    ")\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556959ee-e70c-47e8-a582-f3e407516c24",
   "metadata": {},
   "source": [
    "Define a simple prompt and send it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb88fdd4-2b43-4b21-9a59-0523381124e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Why is the sky blue?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858bbc7-e055-4a2a-b46f-42c2d5780a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(prompt)\n",
    "#response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09213e2f-d2fb-4340-b98a-2ae6031ab26f",
   "metadata": {},
   "source": [
    "Encode a file into a base64 encoded string\n",
    "(this file is a public data set from Kaggle - https://www.kaggle.com/datasets/kyanyoga/sample-sales-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a36319-4cd5-4728-a2cb-0d0bc2b4d1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_file = base64.b64encode(open(\"sales_data_sample.json\", \"rb\").read()).decode(\"utf-8\")\n",
    "\n",
    "file_content = Part.from_data(\n",
    "    data=base64.b64decode(encoded_file), mime_type=\"text/plain\"\n",
    ")\n",
    "# supported mime types at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d4915-2d78-4234-b211-a343bce61e3a",
   "metadata": {},
   "source": [
    "Add the file to the model's context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5dd7c-bcde-4e1f-83b0-4c45e91604f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Add this document to your context. If you are able to process it, provide a simple response that it was successfully uploaded\"\n",
    "gemini_results = chat.send_message([file_content, prompt])\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261696e-5e3f-4568-b796-68b4af750d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"what's in that document?\"\n",
    "gemini_results = chat.send_message(prompt)\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f212c649-c0bc-4eb5-8265-fc21a66bf72c",
   "metadata": {},
   "source": [
    "Encode an image into a base64 encoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611241a-72f9-44d6-89ea-e13c606974dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_file = base64.b64encode(open(\"stuff_on_a_shelf.jpg\", \"rb\").read()).decode(\"utf-8\")\n",
    "\n",
    "image_content = Part.from_data(\n",
    "    data=base64.b64decode(encoded_file), mime_type=\"image/jpeg\"\n",
    ")\n",
    "# supported mime types at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d560166-4a5a-4c33-85ff-42e8a9b1301a",
   "metadata": {},
   "source": [
    "Add the image to the model's context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f193f-02a1-4f6c-9c37-b4d09df8949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"what about this file?\"\n",
    "gemini_results = chat.send_message([image_content, prompt])\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccad388-10df-40a0-8dbc-5863801f1907",
   "metadata": {},
   "source": [
    "Verify the model has access to both the file and the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114204d-1ba9-45fa-9395-676c003ed28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"OK, how many text and image files have we added to your context window so far?\"\n",
    "gemini_results = chat.send_message(prompt)\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882156d2-fe0a-44f5-aa6c-ffe4810f594d",
   "metadata": {},
   "source": [
    "Define a function to make the interaction with the model cleaner from a programming perspective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3c29a-5ce2-48e9-b809-7592c687e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        #role = chunk.candidates[0].content.role)\n",
    "        text_response.append(chunk.text)\n",
    "    #print(chat.history)\n",
    "    return \"\".join(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee9779-80cb-4747-ae71-cb1a857aee67",
   "metadata": {},
   "source": [
    "Send some conversational prompts and print the output showing the roles (i.e. like a more traditional chat bot with user: and gemini:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b3cde-89b0-443a-b57a-2824687ceaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Hello.\"\n",
    "print('user: ' + prompt)\n",
    "print('gemini: ' + get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67751e71-4bce-4b3e-a51e-49bd2461fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me more about that image.\"\n",
    "print('user: ' + prompt)\n",
    "print('gemini: ' + get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be93f14a-2b97-4aac-bded-b81807101fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print('user: ' + prompt)\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d153d9f-1fcd-4e06-9471-b3f1066c7991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Why does it appear when it rains?\"\n",
    "print('user: ' + prompt)\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df105138-6351-42ff-86fa-0179e7159066",
   "metadata": {},
   "source": [
    "Define a new function that will output the respoonse in a stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c8121-78b9-4e0e-85f5-505a599aeadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_chat_response_stream(chat: ChatSession, prompt: str) -> str:\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        print(chunk.text)\n",
    "        #print(chunk)\n",
    "        #return chunk.text\n",
    "    #return \"\".join(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8695970-d412-449f-9ff2-72658122735b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Hello.\"\n",
    "get_chat_response_stream(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9828d90-c631-4ea1-bb2c-3ba7cfdb6e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print('user: ' + prompt)\n",
    "get_chat_response_stream(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0b643-7d4a-4dbf-ade3-737edf9e2b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Why does it appear when it rains?\"\n",
    "get_chat_response_stream(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492d3a8-1540-4d37-8a7b-ce1f0b7c08da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
