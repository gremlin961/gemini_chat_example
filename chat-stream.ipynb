{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bf6c5b-b6c3-4eea-a07c-9302314065d8",
   "metadata": {},
   "source": [
    "Copyright 2024 Google, LLC. This software is provided as-is,\n",
    "without warranty or representation for any use or purpose. Your\n",
    "use of it is subject to your agreement with Google.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "# Gemini Chat Example\n",
    "\n",
    "This notebook provides a simple example for interacting with Google's Gemini models for chat using Vertex AI. For more information please visit https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-chat-prompts-gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe49d241-94f3-4685-94dc-4c0ec21208da",
   "metadata": {},
   "source": [
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55800605-c9b1-40c9-8c12-fb17de2876a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part, Tool, ChatSession, FunctionDeclaration\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "from vertexai.preview.generative_models import grounding\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470424ae-972c-4f13-b3e0-15e50432f5c6",
   "metadata": {},
   "source": [
    "Set your project variables. Change \"YOUR_PROJECT_ID\" to your GCP project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a33169-d938-4185-8a08-d48cbee56958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"YOU_PROJECT_ID\"\n",
    "location = \"global\"\n",
    "region = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b485a0d-aaa3-4f04-b411-3198c3e3d6f8",
   "metadata": {},
   "source": [
    "Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e18c7a8-c4e8-4002-bf95-36def8fb580f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-001\",\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    ")\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51680851-4f7e-45f1-9b3f-18b5c86dec1a",
   "metadata": {},
   "source": [
    "## Start with a simple chat session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556959ee-e70c-47e8-a582-f3e407516c24",
   "metadata": {},
   "source": [
    "Define a simple prompt and send it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb88fdd4-2b43-4b21-9a59-0523381124e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Why is the sky blue?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e858bbc7-e055-4a2a-b46f-42c2d5780a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\n",
      "\n",
      "* **Sunlight and Colors:** Sunlight, while appearing white, is actually a mixture of all the colors of the rainbow.\n",
      "* **Earth's Atmosphere:** Our atmosphere is made up of tiny particles like nitrogen and oxygen molecules.\n",
      "* **Scattering of Light:** When sunlight enters the atmosphere, it collides with these particles. This collision causes the light to scatter in different directions.\n",
      "* **Blue Light's Advantage:** Blue and violet light have shorter wavelengths compared to other colors in the spectrum. This means they are scattered more effectively by the atmospheric particles.\n",
      "* **Our Perception:** Our eyes are more sensitive to blue light than violet. As a result, we perceive the sky as blue due to the scattered blue light reaching our eyes from all directions.\n",
      "\n",
      "**In simpler terms:** Imagine throwing a white ball at a bunch of small objects. The ball represents sunlight, and the objects represent air molecules. The ball (light) bounces off in different directions (scatters). Blue and violet parts of the ball bounce off more easily and in more directions, making them more visible to us.\n",
      "\n",
      "**Why not violet then?** While violet light scatters even more than blue, our eyes are less sensitive to it. Additionally, sunlight contains less violet light compared to blue.\n",
      "\n",
      "**Sunset and Sunrise Colors:** During sunrise and sunset, the sunlight travels through a larger portion of the atmosphere. This causes the blue light to scatter away, allowing longer wavelengths like orange and red to reach our eyes, creating those beautiful hues. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(prompt)\n",
    "#response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac1317-603f-41d5-b84f-9249cc9b9826",
   "metadata": {},
   "source": [
    "## Now let's upload some files to the model and ask questions about them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09213e2f-d2fb-4340-b98a-2ae6031ab26f",
   "metadata": {},
   "source": [
    "Encode a file into a base64 encoded string\n",
    "(this file is a public data set from Kaggle - https://www.kaggle.com/datasets/kyanyoga/sample-sales-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a36319-4cd5-4728-a2cb-0d0bc2b4d1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_file = base64.b64encode(open(\"sales_data_sample.json\", \"rb\").read()).decode(\"utf-8\")\n",
    "\n",
    "file_content = Part.from_data(\n",
    "    data=base64.b64decode(encoded_file), mime_type=\"text/plain\"\n",
    ")\n",
    "# supported mime types at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d4915-2d78-4234-b211-a343bce61e3a",
   "metadata": {},
   "source": [
    "Add the file to the model's context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d5dd7c-bcde-4e1f-83b0-4c45e91604f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. I've got the sales data. What would you like to do with it? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Add this document to your context. If you are able to process it, provide a simple response that it was successfully uploaded\"\n",
    "gemini_results = chat.send_message([file_content, prompt])\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b261696e-5e3f-4568-b796-68b4af750d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document contains sales data for various food, pet care, and snack products. It includes details like order numbers, quantities, prices, sales dates, customer information, and deal sizes.  \n",
      "\n",
      "What kind of information are you interested in? I can tell you things like:\n",
      "\n",
      "* **Total sales for a specific product**\n",
      "* **Average deal size in a particular country**\n",
      "* **Number of orders shipped in a given month**\n",
      "\n",
      "Just let me know what you'd like to explore! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what's in that document?\"\n",
    "gemini_results = chat.send_message(prompt)\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f212c649-c0bc-4eb5-8265-fc21a66bf72c",
   "metadata": {},
   "source": [
    "Encode an image into a base64 encoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e611241a-72f9-44d6-89ea-e13c606974dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_file = base64.b64encode(open(\"stuff_on_a_shelf.jpg\", \"rb\").read()).decode(\"utf-8\")\n",
    "\n",
    "image_content = Part.from_data(\n",
    "    data=base64.b64decode(encoded_file), mime_type=\"image/jpeg\"\n",
    ")\n",
    "# supported mime types at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d560166-4a5a-4c33-85ff-42e8a9b1301a",
   "metadata": {},
   "source": [
    "Add the image to the model's context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67f193f-02a1-4f6c-9c37-b4d09df8949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file is a picture of a shelf at a store with various cleaning products. The picture shows brands like Pledge, Old English, Method, Weiman, and Resolve. It also shows prices for the products. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what about this file?\"\n",
    "gemini_results = chat.send_message([image_content, prompt])\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccad388-10df-40a0-8dbc-5863801f1907",
   "metadata": {},
   "source": [
    "Verify the model has access to both the file and the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c114204d-1ba9-45fa-9395-676c003ed28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a large language model, I don't have a persistent memory or a \"context window\" in the way you might be thinking. Each time we interact, I process your request and the information you provide anew. \n",
      "\n",
      "So, while I can access and process the sales data and the image you provided during our current conversation, I won't remember them once the conversation ends. \n",
      "\n",
      "Does that make sense? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"OK, how many text and image files have we added to your context window so far?\"\n",
    "gemini_results = chat.send_message(prompt)\n",
    "print(gemini_results.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beaee3b-b3d8-4660-876e-5751a5a6d510",
   "metadata": {},
   "source": [
    "## Let's make this code a little cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882156d2-fe0a-44f5-aa6c-ffe4810f594d",
   "metadata": {},
   "source": [
    "Define a function to make the interaction with the model cleaner from a programming perspective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd3c29a-5ce2-48e9-b809-7592c687e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_chat_response(chat: ChatSession, prompt: str) -> str:\n",
    "    text_response = []\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        #role = chunk.candidates[0].content.role)\n",
    "        text_response.append(chunk.text)\n",
    "    #print(chat.history)\n",
    "    return \"\".join(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee9779-80cb-4747-ae71-cb1a857aee67",
   "metadata": {},
   "source": [
    "Send some conversational prompts and print the output showing the roles (i.e. like a more traditional chat bot with user: and gemini:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3b3cde-89b0-443a-b57a-2824687ceaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Hello.\n",
      "gemini: Hello! ðŸ‘‹ How can I help you today? ðŸ˜Š \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello.\"\n",
    "print('user: ' + prompt)\n",
    "print('gemini: ' + get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67751e71-4bce-4b3e-a51e-49bd2461fa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Tell me more about that image.\n",
      "gemini: Please provide me with the image you are referring to! I need to see it to tell you more about it. ðŸ˜Š \n",
      "\n",
      "You can describe it, or if you've already shared it in our conversation, just let me know and I can refer back to it. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me more about that image.\"\n",
    "print('user: ' + prompt)\n",
    "print('gemini: ' + get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be93f14a-2b97-4aac-bded-b81807101fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What are all the colors in a rainbow?\n",
      "The colors of a rainbow, in order, are:\n",
      "\n",
      "* **Red**\n",
      "* **Orange**\n",
      "* **Yellow**\n",
      "* **Green**\n",
      "* **Blue**\n",
      "* **Indigo**\n",
      "* **Violet**\n",
      "\n",
      "This is often remembered by the acronym **ROYGBIV**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print('user: ' + prompt)\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d153d9f-1fcd-4e06-9471-b3f1066c7991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Why does it appear when it rains?\n",
      "You're right to connect rain and rainbows! Rainbows appear when it rains because:\n",
      "\n",
      "* **Sunlight:** You need sunlight to create a rainbow.\n",
      "* **Water Droplets:** Rain provides the water droplets that act like tiny prisms.\n",
      "* **Refraction and Reflection:** When sunlight enters a water droplet, it bends (refracts) and bounces off the inside (reflects). This separates the white sunlight into its different colors.\n",
      "* **Angle:**  The angle between the sun, the water droplets, and your eyes needs to be just right (around 42 degrees) for you to see the rainbow.\n",
      "\n",
      "**In simpler terms:** Imagine sunlight shining through a bunch of tiny, round mirrors (the raindrops). The mirrors bend and bounce the light, splitting it into the colors of the rainbow. You see the rainbow when you're standing in the right spot to catch those colorful reflections. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Why does it appear when it rains?\"\n",
    "print('user: ' + prompt)\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40be38-325c-4617-b492-cff919b9b27e",
   "metadata": {},
   "source": [
    "## Let's see how to use streaming responses to enhance the interaction and reduce the perceived latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df105138-6351-42ff-86fa-0179e7159066",
   "metadata": {},
   "source": [
    "Define a new function that will output the respoonse in a stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834c8121-78b9-4e0e-85f5-505a599aeadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_chat_response_stream(chat: ChatSession, prompt: str) -> str:\n",
    "    responses = chat.send_message(prompt, stream=True)\n",
    "    for chunk in responses:\n",
    "        print(chunk.text)\n",
    "        #print(chunk)\n",
    "        #return chunk.text\n",
    "    #return \"\".join(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8695970-d412-449f-9ff2-72658122735b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "! ðŸ‘‹  It's nice to hear from you. What can I do\n",
      " for you today? ðŸ˜Š \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello.\"\n",
    "get_chat_response_stream(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9828d90-c631-4ea1-bb2c-3ba7cfdb6e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What are all the colors in a rainbow?\n",
      "The\n",
      " colors of the rainbow, in order, are:\n",
      "\n",
      "* **Red**\n",
      "\n",
      "* **Orange**\n",
      "* **Yellow**\n",
      "* **Green**\n",
      "*\n",
      " **Blue**\n",
      "* **Indigo**\n",
      "* **Violet**\n",
      "\n",
      "A helpful acronym to remember the order is **ROYGBIV**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are all the colors in a rainbow?\"\n",
    "print('user: ' + prompt)\n",
    "get_chat_response_stream(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef0b643-7d4a-4dbf-ade3-737edf9e2b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain\n",
      "bows are actually not directly caused by rain itself, but rather by the presence of\n",
      " water droplets in the air after or during rainfall. Here's how it works\n",
      ":\n",
      "\n",
      "* **Sunlight:** Rainbows need sunlight to form.\n",
      "* **Water Droplets:** The air is filled with water droplets after it rains. These\n",
      " droplets act like tiny prisms.\n",
      "* **Refraction:** When sunlight enters a water droplet, it bends (refracts) as it passes from air to\n",
      " water.\n",
      "* **Dispersion:**  Different colors of light bend at slightly different angles. This process, called dispersion, separates the white sunlight into its spectrum of colors.\n",
      "* **Reflection:** The light then reflects off the inside surface\n",
      " of the water droplet.\n",
      "* **Second Refraction:** As the light exits the droplet, it refracts again, further separating the colors.\n",
      "* **Observer's Perspective:** You see a rainbow when you are positioned so that the\n",
      " refracted and reflected light from the water droplets reaches your eyes. The angle between the sun, the water droplets, and your eyes needs to be just right (around 42 degrees).\n",
      "\n",
      "**In simpler terms:** Imagine sunlight shining through a bunch of tiny, round crystals (the raindrops). The crystals bend and\n",
      " bounce the light, splitting it into the colors of the rainbow. You see the rainbow when you're standing in the right spot to catch those colorful reflections. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Why does it appear when it rains?\"\n",
    "get_chat_response_stream(chat, prompt)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
